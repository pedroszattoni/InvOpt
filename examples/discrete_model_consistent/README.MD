# `discrete_model_consistent`

Given the a dataset of signal-response data $\mathcal{D} = \\{(\hat{s}_ i, \hat{x}_ i)\\}_ {i=1}^N$, the FOP
$$\min_ {x \in \mathbb{X}(\hat{s}_ i)} \ \theta^\top \phi(\hat{s}_ i,x),$$ and assuming there exists a cost vector $\theta^\star$ consistent with the dataset, that is, such that $x_ i \in \arg\min_ {x \in \mathbb{X}(\hat{s}_ i)} \ {\theta^\star}^\top \phi(\hat{s}_ i,x)$. The `discrete_model_consistent` function solves the IO problem (by default) using the *incenter stratety*

$$
\begin{aligned}
 \min_ {\theta} \quad & \mathcal{R} (\theta - \hat{\theta}) \\ 
 \text{s.t.} \quad & \theta^\top \big(\phi(\hat{s}_ i,\hat{x}_ i) - \phi(\hat{s}_ i,x_ i) \big) + d(\hat{x}_ i,x_ i)\leq 0 \quad\quad \forall x_ i \in \mathbb{X}(\hat{s}_ i), \ \forall i \in [N] \\
 & \theta \in \Theta, 
\end{aligned}
$$

where
- $\hat{\theta}$ is an a priory belief or estimate of the true cost vector.
- $\mathcal{R} : \mathbb{R}^p \to \mathbb{R}$ is a regularization function.
- $\phi: \mathbb{S} \times \mathbb{X} \to \mathbb{R}^p$ is the feature mapping, which maps a signal-response pair $(s,x)$ to a feature vector $\phi(s,x)$. In practice, choosing a suitable mapping $\phi$ is part of the modeling of the problem.
- $d : \mathbb{X} \times \mathbb{X} \to \mathbb{R}_+$ is a distance function, which given two responses, returns the distance between them according to some distance metric.
- $\mathbb{X}(\hat{s}_ i)$ is the constraint set of the FOP, which is assumed to be discrete since we need to be able to list all $x_ i \in \mathbb{X}(\hat{s}_ i)$.
- $\Theta$ is the set used to encode any prior information or assumption we may have on the expert's true cost function, e.g., nonnegativity of the cost vector.

Alternatevely, the `discrete_model_consistent` function also implements the so-called *feasibility strategy*, which solves the IO problem by solving the feasibility problem

$$
\begin{aligned} \min_ {\theta} \quad & 0 \\
\text{s.t.} \quad & \theta^\top \big(\phi(\hat{s}_ i,\hat{x}_ i) - \phi(\hat{s}_ i,x_ i) \big) \leq 0 \quad\quad \forall x_ i \in \mathbb{X}(\hat{s}_ i), \ \forall i \in [N] \\
& \theta \in \Theta, \quad \rVert \theta \rVert = 1,\end{aligned}
$$

where the norm equality constraint is the $\ell_ 1$ norm if $\Theta = \{\theta \in \mathbb{R}^p : \theta \geq 0\}$, and the $\ell_ \infty$ norm otherwise.

## Example: binary linear program with consistent data

In the file `binary_LP_consistent_data.py`, you will find an example usage of the `discrete_model_consistent` function. For this example, the dataset $\mathcal{D} = \{(\hat{s}_ i, \hat{x}_ i)\}_ {i=1}^N$ is generated by solving the binary linear program

$$
\begin{aligned}
\min_ {x} \quad & \langle \theta, x \rangle \\
\text{s.t.} \quad & Ax \leq b \\
& x \in \{0,1\}^n,
\end{aligned}
$$

and the IO problem is solved using the incenter and feasibilty strategies from `discrete_model_consistent`, as well as the circumcenter strategy from [Besbes et al. (2022)](https://arxiv.org/abs/2106.14015). For a detailed description of this example, please see [Zattoni Scroccaro et al. (2023)](https://arxiv.org/abs/0000.00000)