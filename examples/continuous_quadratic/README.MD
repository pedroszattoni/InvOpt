# `continuous_quadratic`

>Warning: the `continuous_quadratic` function requires `cvxpy`.

## Use cases

This function is can be used when the FOP is of the form

$$
\min_ {x \in \mathbb{X}(\hat{s})} \ \langle \theta,\phi(\hat{s}, x) \rangle
$$

with a continuous constraint set

$$
\mathbb{X}(\hat{s}) = \left\\{ x \in \mathbb{R}^n : \hat{A}x \leq \hat{b} \right\\},
$$

where $\hat{s} = (\hat{A}, \hat{b}, \hat{w})$ and hypothesis function

$$
\langle \theta,\phi(\hat{s}, x) \rangle = \langle x,Q_ {xx} x \rangle  + \langle x,Q \phi_ 1(\hat{w}) \rangle,
$$

where $\theta = [\text{vec}(Q_ {xx}) \ \ \text{vec}(Q)]$, and $\phi_ 1$ is a feature function.

## Solution method

We define $\gamma_ k \in \mathbb{R}^n$ equal the vector of zeros except for the $k$'th element, which equals $1$ if $k \leq n$. If $k > n$, then the $\text{mod}(k,n)$'th element equals $-1$. Given the a dataset of signal-response data $\mathcal{D} = \\{(\hat{s}_ i, \hat{x}_ i)\\}_ {i=1}^N$,  the `continuous_quadratic` function solves the IO problem using


$$
\begin{aligned}
\min_{\theta, \beta_ i, \lambda_ {ik}, \alpha_ {ik}} \quad & \kappa\mathcal{R}(\theta - \hat{\theta}) + \frac{1}{N}\sum_ {i=1}^N \beta_ i  \\
\text{s.t.} \quad \quad & \langle \theta,\phi(\hat{s}_ i,\hat{x}_ i) \rangle + \alpha_ {ik} + \langle \lambda_ {ik},\hat{c}_ i \rangle + \langle \gamma_ k,\hat{x}_ i \rangle  \leq \beta_ i & \forall i \in [N], \ \forall k \in [2n] \\
& \begin{bmatrix}
    Q_ {xx} & Q \phi_ 1(\hat{w}_ i) + \gamma_ k + \hat{A}_ i^\top \lambda_ {ik} \\
    * & 4\alpha_ {ik}
    \end{bmatrix} \succcurlyeq 0 & \forall i \in [N], \ \forall k \in [2n] \\
& \theta \in \Theta, \quad \beta_i \geq 0, \quad \lambda_ {ik} \geq 0 & \forall i \in [N], \ \forall k \in [2n],
\end{aligned}
$$

where
- $\hat{\theta} \in \mathbb{R}^p$ is an a priory belief or estimate of the true cost vector. *(optional)*
- $\mathcal{R} : \mathbb{R}^p \to \mathbb{R}$ is a regularization function.
- $\kappa$ is a nonnegative regularization parameter.
- $\phi_ 1: \mathbb{W} \times \to \mathbb{R}^m$ is the feature mapping, which maps a signal-response pair $\hat{w}$ to a feature vector $\phi_ 1(\hat{w})$.
- $\Theta$ is the set used to encode any prior information or assumption we may have on the expert's true cost function, e.g., nonnegativity of the cost vector. *(optional)*

Alternatively, if the distance penalization function $d_ z$  is not provided and $\kappa=0$ or $\hat{\theta}$ is not provided, the `continuous_quadratic` function solves the IO problem using the *Suboptimality loss*-based reformulation

$$
\begin{aligned}
\min_{\theta, \beta_ i, \lambda_ {i}, \alpha_ {i}} \quad & \frac{1}{N}\sum_ {i=1}^N \beta_ i  \\
\text{s.t.} \quad \quad & \langle \theta,\phi(\hat{s}_ i,\hat{x}_ i) \rangle + \alpha_ {i} + \langle \lambda_ {i},\hat{c}_ i \rangle  \leq \beta_ i & \forall i \in [N] \\
& \begin{bmatrix}
    Q_ {xx} & Q \phi_ 1(\hat{w}_ i) + \hat{A}_ i^\top \lambda_ {i} \\
    * & 4\alpha_ {i}
    \end{bmatrix} \succcurlyeq 0 & \forall i \in [N] \\
& \theta \in \Theta, \quad \text{Tr}(Q_ {xx}) = 1, \quad \beta_ i \geq 0, \quad \lambda_ {i} \geq 0 & \forall i \in [N],
\end{aligned}
$$

where trace equality constraint $\text{Tr}(Q_ {xx}) = 1$ constraint must be added to exclude the trivial solution $\theta = 0$.

## Example: quadratic program

In the file `QP.py`, you will find an example usage of the `continuous_quadratic` function. For this example, the dataset $\mathcal{D} = \\{(\hat{s}_ i, \hat{x}_ i)\\}_ {i=1}^N$ is generated by solving the binary quadratic program

$$
\begin{aligned}
\hat{x}_ i \in \arg\min_ {x} \quad &  \langle x,Q_{xx} x \rangle  + \langle x,q \rangle \\
\text{s.t.} \quad & \hat{A}_ i x \leq \hat{b}_ i \\
& 0 \leq x \leq 1,
\end{aligned}
$$

where $\hat{s}_ i = ([\hat{A}_ i^\top \ \ I \ \ -I]^\top, [\hat{b}_ i \ \ \mathbf{1} \ \ \mathbf{0}], 0)$, where $\mathbf{1}$ is the vector of ones and $\mathbf{0}$ is the vector of zeros. The IO problem is solved using the solution methods presented above, with $Q = q$ and $\phi_ 1(\hat{w}) = 1$. The way the synthetic data is generated and the way the results are evaluated follow the same template as the numerical experiments in [Zattoni Scroccaro et al. (2023)](https://arxiv.org/abs/2305.07730).