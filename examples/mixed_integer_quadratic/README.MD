# `mixed_integer_quadratic`

>Warning: the `mixed_integer_quadratic` function requires `cvxpy`.

## Use cases

This function is can be used when the FOP is of the form

$$
\min_ {x \in \mathbb{X}(\hat{s})} \ \theta^\top \phi(\hat{s}, x)
$$

with a mixed-integer constraint set

$$
\mathbb{X}(\hat{s}) = \left\\{ x=(y,z) \in \mathbb{R}^u \times \mathbb{Z}^v : \hat{A}y + \hat{B}z \leq \hat{c}, \ z \in \mathbb{Z}(\hat{w}) \right\\},
$$

where $\hat{s} = (\hat{A}, \hat{B}, \hat{c}, \hat{w})$ and $\mathbb{Z}(\hat{w})$ is a bounded set that may depend on a signal $\hat{w}$, and hypothesis function

$$
\theta^\top \phi(\hat{s}, x) = y^\top Q_ {yy} y + y^\top Q \phi_ 1(\hat{w}, z) + q^\top \phi_ 2(\hat{w}, z) ,
$$

where $x = (y,z)$, $\theta = (\text{vec}(Q_ {yy}), \text{vec}(Q), q)$, and $\phi_ 1$ and $\phi_ 2$ are feature functions.

## Solution method

We define $M_ i = |\mathbb{Z}(\hat{w}_ i)|$ and use the following indexing notation for the elements of $\mathbb{Z}(\hat{w}_ i) = \\{z_ {i1},\ldots,z_ {ij},\ldots,z_ {iM_ i}\\}$. Given the a dataset of signal-response data $\mathcal{D} = \\{(\hat{s}_ i, \hat{x}_ i)\\}_ {i=1}^N$,  the `mixed_integer_linear` function solves the IO problem using

$$
\begin{aligned}
\min_{\theta, \beta_ i, \lambda_ {ij}, \alpha_ {ij}} \quad & \kappa\mathcal{R}(\theta - \hat{\theta}) + \frac{1}{N}\sum_ {i=1}^N \beta_ i  \\
\text{s.t.} \quad \quad & \theta^\top \phi(\hat{s}_ i,\hat{x}_ i) + \alpha_ {ij} + \lambda_ {ij}^\top (\hat{c}_ i - \hat{B}_ i z_ {ij}) - q^\top \phi_ 2(\hat{w}_ i, z_ {ij}) + d_ z(\hat{z}_ i, z_ {ij}) \leq \beta_ i & \forall i \in [N], \ \forall j \in [M_ i] \\
& \begin{bmatrix}
    Q_ {yy} & Q \phi_ 1(\hat{w}_ i, z_ {ij}) + \hat{A}_ i^\top \lambda_ {ij} \\
    * & 4\alpha_ {ij}
    \end{bmatrix} \succcurlyeq 0 & \forall i \in [N], \ \forall j \in [M_ i] \\
& \theta \in \Theta, \quad \beta_i \geq 0, \quad \lambda_ {ij} \geq 0 & \forall i \in [N], \ \forall j \in [M_ i],
\end{aligned}
$$

where
- $\hat{\theta} \in \mathbb{R}^p$ is an a priory belief or estimate of the true cost vector.
- $\mathcal{R} : \mathbb{R}^p \to \mathbb{R}$ is a regularization function.
- $\kappa$ is a nonnegative regularization parameter.
- $\phi_ 1: \mathbb{W} \times \mathbb{Z}^v \to \mathbb{R}^m$ is the feature mapping, which maps a signal-response pair $(w,z)$ to a feature vector $\phi_ 1(w,z)$.
- $\phi_ 2: \mathbb{W} \times \mathbb{Z}^v \to \mathbb{R}^n$ is the feature mapping, which maps a signal-response pair $(w,z)$ to a feature vector $\phi_ 2(w,z)$.
- $d_ z : \mathbb{Z}^v \times \mathbb{Z}^v \to \mathbb{R}_ +$ is a distance function, which given the integer part of two responses, returns the distance between them according to some distance metric.
- $\mathbb{Z}(\hat{w}_ i)$ is the constraint set of the integer part of the decision vector.
- $\Theta$ is the set used to encode any prior information or assumption we may have on the expert's true cost function, e.g., nonnegativity of the cost vector.

Alternatively, the `discrete_model` function also implements a *Suboptimality loss*-based approach to solving IO problem

$$
\begin{aligned}
\min_{\theta, \beta_ i, \lambda_ {ij}, \alpha_ {ij}} \quad & \kappa\mathcal{R}(\theta - \hat{\theta}) + \frac{1}{N}\sum_ {i=1}^N \beta_ i  \\
\text{s.t.} \quad \quad & \theta^\top \phi(\hat{s}_ i,\hat{x}_ i) + \alpha_ {ij} + \lambda_ {ij}^\top (\hat{c}_ i - \hat{B}_ i z_ {ij}) - q^\top \phi_ 2(\hat{w}_ i, z_ {ij})  \leq \beta_ i & \forall i \in [N], \ \forall j \in [M_ i] \\
& \begin{bmatrix}
    Q_ {yy} & Q \phi_ 1(\hat{w}_ i, z_ {ij}) + \hat{A}_ i^\top \lambda_ {ij} \\
    * & 4\alpha_ {ij}
    \end{bmatrix} \succcurlyeq 0 & \forall i \in [N], \ \forall j \in [M_ i] \\
& \theta \in \Theta, \quad \beta_ i \geq 0, \quad \lambda_ {ij} \geq 0 & \forall i \in [N], \ \forall j \in [M_ i].
\end{aligned}
$$

If $\kappa=0$ or $\hat{\theta}$ is not provided, we need to add the trace equality constraint $\text{Tr}(Q_ {yy}) = 1$ to exclude the trivial solution $\theta=0$.

## Example: binary quadratic mixed-interger program

In the file `MIQP.py`, you will find an example usage of the `mixed_integer_quadratic` function. For this example, the dataset $\mathcal{D} = \\{(\hat{s}_ i, \hat{x}_ i)\\}_ {i=1}^N$ is generated by solving the binary linear program

$$
\begin{aligned}
\hat{x}_ i = (\hat{y}_ i, \hat{z}_ i) \in \arg\min_ {y, z} \quad &  y^\top Q_{yy} y + y^\top Q_{yz} z + q_ y^\top y + q_ z^\top z \\
\text{s.t.} \quad & A_ i y + B_ i z \leq c_ i \\
& 0 \leq y \leq 1, \quad z \in \\{0,1\\}^n,
\end{aligned}
$$

where $\hat{s}_ i = (A_ i, B_ i, c_ i, 0)$, and the IO problem is solved using the solution methods presented above, with $\phi_ 1(w,z) = [z^\top \ 1]^\top$ and $\phi_ 2(w,z) = z$. The way the synthetic data is generated and the way the results are evaluated follow the same template as the numerical experiments in [Zattoni Scroccaro et al. (2023)](https://arxiv.org/abs/2305.07730).

## Example: simultanious classification and regression

The `mixed_integer_quadratic` function can also be used for simultanious classification and regression for supervised learning problems. In the file `simultanious_regression_classification.py`, you will find an example using the [Breast Cancer Wisconsin (Diagnostic) dataset](https://archive-beta.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic). For a detailed description of this example, please see [Zattoni Scroccaro et al. (2023)](https://arxiv.org/abs/2305.07730).