- Test case when (some of) the data response examples x_hat are not feasible w.r.t. X(s_hat). For the FOM function, we need to check if the loss value is negative. If negative, set the subgradient to zero. See remark on Remark 4.2  on infeasible decisions in Zattoni Scroccaro et al. "Learning in Inverse Optimization: Incenter Cost, Augmented Suboptimality Loss, and Algorithms"

- Implement the option to use open source solver instead of Gurobi.

- Implement multiprocessing option?

- Implement (approximate) polyak step size?

- Implement dual averaging and AdaGrad algorithms.

- Implement cutting-plane / (proximal) bundle algorithms.

- Implement more options for decision spaces, for example:
	- Add the option for "one-hot" decision spaces.
	- Add the option for the user to input a list with all elements of X.
	- Allow for general integer inputs. The binary case can be seen as a special case for integer inputs bounded by 0 and 1.

- Implement/test aProx and step-size modification using two linear approximations.

- Add IO scenarios from https://arxiv.org/pdf/2102.10742.pdf as examples.

- Add option to use scipy.optimize.minimize algorithms to optimize the Augmented Suboptimality Loss?

- Implement Shorâ€™s r-Algorithm (Space Dilation Method). See "Introduction to Nonsmooth Optimization Theory, Practice and Software".

- Add other options for constraint set Theta.

- Add the option for consistent data for mixed-integer cases?

- Add support to theta_hat for MIP cases?